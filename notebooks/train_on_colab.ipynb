{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f84a1c6",
   "metadata": {},
   "source": [
    "# ðŸš€ Image Classification Training on Google Colab (Free GPU)\n",
    "\n",
    "**This notebook allows you to train your models with FREE GPU access!**\n",
    "\n",
    "## Setup Instructions:\n",
    "1. Go to: https://colab.research.google.com/\n",
    "2. Upload this notebook (File â†’ Upload notebook)\n",
    "3. Enable GPU: Runtime â†’ Change runtime type â†’ GPU â†’ Save\n",
    "4. Run all cells!\n",
    "\n",
    "**Training time: ~30 minutes with GPU vs 8+ hours on CPU!** âš¡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3813e9",
   "metadata": {},
   "source": [
    "## Step 1: Setup Project Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf3a5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"ðŸ”¥ GPU Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"âš ï¸  GPU not enabled! Go to Runtime â†’ Change runtime type â†’ GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b940b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q timm albumentations opencv-python omegaconf hydra-core tqdm scikit-learn matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a365c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create project structure\n",
    "!mkdir -p configs/model configs/data configs/training\n",
    "!mkdir -p src/data src/models src/training src/utils\n",
    "!mkdir -p checkpoints logs outputs data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6235908",
   "metadata": {},
   "source": [
    "## Step 2: Upload Your Project Files\n",
    "\n",
    "**Option A: Use Google Drive (Recommended)**\n",
    "1. Upload your entire `image_classification` folder to Google Drive\n",
    "2. Run the cell below to mount Drive\n",
    "3. Copy files from Drive\n",
    "\n",
    "**Option B: Upload Manually**\n",
    "- Click the folder icon on the left\n",
    "- Upload your `src/` folder and `configs/` folder\n",
    "\n",
    "**Option C: Copy-paste code (see cells below)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b694c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option A: Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Copy your project from Drive (adjust path as needed)\n",
    "# !cp -r /content/drive/MyDrive/image_classification/* /content/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b9db38",
   "metadata": {},
   "source": [
    "## Step 3: Quick Setup (Copy-Paste Your Code)\n",
    "\n",
    "**If you don't want to upload files, I'll create minimal code here:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329bbc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/models/simple_model.py\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "\n",
    "def create_model(model_name='resnet50', num_classes=10, pretrained=True):\n",
    "    \"\"\"Create model using timm.\"\"\"\n",
    "    model = timm.create_model(\n",
    "        model_name,\n",
    "        pretrained=pretrained,\n",
    "        num_classes=num_classes\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4579ada0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile train_simple.py\n",
    "\"\"\"Simplified training script for Colab.\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "sys.path.insert(0, '/content')\n",
    "from src.models.simple_model import create_model\n",
    "\n",
    "# Configuration\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "BATCH_SIZE = 64 if DEVICE == 'cuda' else 32\n",
    "EPOCHS = 10\n",
    "LR = 0.001\n",
    "\n",
    "print(f\"Training on: {DEVICE}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Epochs: {EPOCHS}\\n\")\n",
    "\n",
    "# Data\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(224, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "val_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"Train samples: {len(train_dataset)}\")\n",
    "print(f\"Val samples: {len(val_dataset)}\\n\")\n",
    "\n",
    "# Model\n",
    "model = create_model('resnet50', num_classes=10, pretrained=True).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "# Training loop\n",
    "best_acc = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    # Train\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{EPOCHS}')\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        pbar.set_postfix({'loss': f'{train_loss/len(pbar):.4f}', 'acc': f'{100.*train_correct/train_total:.2f}%'})\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    val_acc = 100. * val_correct / val_total\n",
    "    scheduler.step()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}: Train Acc: {100.*train_correct/train_total:.2f}% | Val Acc: {val_acc:.2f}%')\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'accuracy': val_acc\n",
    "        }, 'best_model.pth')\n",
    "        print(f'âœ“ Saved best model (acc: {val_acc:.2f}%)')\n",
    "\n",
    "print(f'\\nðŸŽ‰ Training complete! Best accuracy: {best_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf128d20",
   "metadata": {},
   "source": [
    "## Step 4: Train! ðŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f191b9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training\n",
    "!python train_simple.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e685945",
   "metadata": {},
   "source": [
    "## Step 5: Download Your Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316c721b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the trained model\n",
    "from google.colab import files\n",
    "files.download('best_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7ccf13",
   "metadata": {},
   "source": [
    "## Alternative: Use Your Full Project\n",
    "\n",
    "If you uploaded your complete project files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76ad3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have the full project structure, run:\n",
    "# !python scripts/train.py training.epochs=10 data.batch_size=64 device=cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128bc684",
   "metadata": {},
   "source": [
    "## Try Different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff19618c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vision Transformer\n",
    "model_vit = create_model('vit_base_patch16_224', num_classes=10, pretrained=True)\n",
    "print(f\"ViT parameters: {sum(p.numel() for p in model_vit.parameters()):,}\")\n",
    "\n",
    "# EfficientNet\n",
    "model_eff = create_model('efficientnet_b3', num_classes=10, pretrained=True)\n",
    "print(f\"EfficientNet parameters: {sum(p.numel() for p in model_eff.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6add6ca",
   "metadata": {},
   "source": [
    "## Expected Results (10 epochs)\n",
    "\n",
    "- **ResNet50**: ~94% validation accuracy in ~30 minutes\n",
    "- **ViT-Base**: ~95% validation accuracy in ~60 minutes  \n",
    "- **EfficientNet-B3**: ~96% validation accuracy in ~45 minutes\n",
    "\n",
    "## Tips:\n",
    "\n",
    "1. **Check GPU**: Make sure GPU is enabled (see cell 1)\n",
    "2. **Session limit**: Colab free tier has ~12 hour limit\n",
    "3. **Save often**: Download your model periodically\n",
    "4. **Reconnect**: If disconnected, just re-run from training cell\n",
    "\n",
    "## Next Steps:\n",
    "\n",
    "- Try different models (ViT, EfficientNet)\n",
    "- Increase epochs to 50-100 for better results\n",
    "- Experiment with batch size (32, 64, 128)\n",
    "- Add more augmentations\n",
    "\n",
    "**Enjoy your FREE GPU training! ðŸŽ‰**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
